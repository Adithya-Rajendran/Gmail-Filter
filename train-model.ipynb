{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7f8ce5",
   "metadata": {},
   "source": [
    "# Get the dataset\n",
    "\n",
    "Download Data set from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79709f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/jetson/.cache/kagglehub/datasets/naserabdullahalam/phishing-email-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"naserabdullahalam/phishing-email-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239aea24",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import Pandas and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0435e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib # Used for saving the model and vectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b64e0",
   "metadata": {},
   "source": [
    "# --- 1 Load dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206083bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(path + \"/\" + \"CEAS_08.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found. Please update the file path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974d908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " label\n",
      "1    21842\n",
      "0    17312\n",
      "Name: count, dtype: int64\n",
      "                                                body  label\n",
      "0  Buck up, your troubles caused by small dimensi...      1\n",
      "1  \\nUpgrade your sex and pleasures with these te...      1\n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1\n"
     ]
    }
   ],
   "source": [
    "# Weâ€™ll use subject, body, and label\n",
    "needed = [\"subject\", \"body\", \"label\"]\n",
    "missing = [c for c in needed if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}. Found: {df.columns.tolist()}\")\n",
    "\n",
    "# Fill any missing subject or body text with an empty string\n",
    "df[\"subject\"] = df[\"subject\"].fillna(\"\")\n",
    "df[\"body\"] = df[\"body\"].fillna(\"\")\n",
    "\n",
    "# Combine subject and body into a single feature for the model\n",
    "df[\"full_text\"] = df[\"subject\"] + \" \" + df[\"body\"]\n",
    "\n",
    "# Make sure label is 0/1 ints (1=spam, 0=not spam)\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "print(\"Class counts:\\n\", df[\"label\"].value_counts())\n",
    "print(df[[\"body\",\"label\"]].head(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb93b8",
   "metadata": {},
   "source": [
    "# --- 2. Preprocess Text ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0540c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing text data...\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans text data by lowercasing and removing non-alphabetic characters.\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation, numbers, and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"\\nPreprocessing text data...\")\n",
    "df['cleaned_text'] = df['full_text'].apply(preprocess_text)\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7530176",
   "metadata": {},
   "source": [
    "# --- 3. Train/Test Split ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d087c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split into 31323 training and 7831 testing samples.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"cleaned_text\"], df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "print(f\"\\nData split into {len(X_train)} training and {len(X_test)} testing samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fea285",
   "metadata": {},
   "source": [
    "# --- 4. Vectorize Text using TF-IDF ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a0ac496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text vectorized successfully.\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF is effective for text classification because it weighs words by their\n",
    "# importance in a document relative to the entire corpus.[5, 6]\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Use top 5000 most frequent words\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test) # Use the same vectorizer for the test set\n",
    "print(\"\\nText vectorized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a434a6",
   "metadata": {},
   "source": [
    "# --- 5. Train Logistic Regression Model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab2f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Iteration 1, loss = 0.16512683\n",
      "Validation score: 0.993936\n",
      "Iteration 2, loss = 0.01190227\n",
      "Validation score: 0.996170\n",
      "Iteration 3, loss = 0.00539006\n",
      "Validation score: 0.996489\n",
      "Iteration 4, loss = 0.00307873\n",
      "Validation score: 0.995851\n",
      "Iteration 5, loss = 0.00188391\n",
      "Validation score: 0.996170\n",
      "Iteration 6, loss = 0.00141129\n",
      "Validation score: 0.996170\n",
      "Iteration 7, loss = 0.00114987\n",
      "Validation score: 0.996170\n",
      "Iteration 8, loss = 0.00095550\n",
      "Validation score: 0.994893\n",
      "Iteration 9, loss = 0.00091284\n",
      "Validation score: 0.995531\n",
      "Iteration 10, loss = 0.00107685\n",
      "Validation score: 0.996489\n",
      "Iteration 11, loss = 0.00115242\n",
      "Validation score: 0.996489\n",
      "Iteration 12, loss = 0.00094435\n",
      "Validation score: 0.994893\n",
      "Iteration 13, loss = 0.00093437\n",
      "Validation score: 0.994893\n",
      "Iteration 14, loss = 0.00103633\n",
      "Validation score: 0.993297\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression is a simple, efficient, and highly effective model for\n",
    "# binary text classification tasks like spam detection.[7, 8, 9]\n",
    "# model = LogisticRegression()\n",
    "# model = MultinomialNB()\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,50), \n",
    "    max_iter=200,  # Increase this if the model doesn't converge\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    # random_state=42,\n",
    "    early_stopping=True,\n",
    "    verbose=True # Shows training progress\n",
    ")\n",
    "\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3095b2",
   "metadata": {},
   "source": [
    "# --- 6. Evaluate the Model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a74004dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.9955\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3447   15]\n",
      " [  20 4349]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    not spam       0.99      1.00      0.99      3462\n",
      "        spam       1.00      1.00      1.00      4369\n",
      "\n",
      "    accuracy                           1.00      7831\n",
      "   macro avg       1.00      1.00      1.00      7831\n",
      "weighted avg       1.00      1.00      1.00      7831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Model Evaluation ---\")\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['not spam', 'spam']))\n",
    "# For spam, high precision is crucial to avoid misclassifying important emails (false positives).[10, 11, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9644a36",
   "metadata": {},
   "source": [
    "# --- 7. Save the Model and Vectorizer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7690fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model and vectorizer saved to disk as 'spam_classifier_model.pkl' and 'tfidf_vectorizer.pkl'\n"
     ]
    }
   ],
   "source": [
    "# We save both the model and the vectorizer so we can use them later\n",
    "# to make predictions on new, unseen emails.\n",
    "joblib.dump(model, 'model/spam_classifier_model.pkl')\n",
    "joblib.dump(vectorizer, 'model/tfidf_vectorizer.pkl')\n",
    "print(\"\\nModel and vectorizer saved to disk as 'spam_classifier_model.pkl' and 'tfidf_vectorizer.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
